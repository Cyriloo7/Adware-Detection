{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mb9gwprd99kL"
   },
   "source": [
    "# ISM Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Header and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:18.437380Z",
     "start_time": "2023-04-03T00:41:18.421589Z"
    },
    "id": "Q4ME1HZ198hS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:19.997918Z",
     "start_time": "2023-04-03T00:41:19.162438Z"
    },
    "id": "zOFwFbcchTvW"
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:20.258800Z",
     "start_time": "2023-04-03T00:41:20.004437Z"
    },
    "id": "O3B2KXLL-Wp4"
   },
   "outputs": [],
   "source": [
    "\n",
    "data1=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_13_2017-ad-ewind-koodous-1d.csv')\n",
    "data2=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_13_2017-ad-feiwo-fortinet-04c12809d3b1809c9980bd1e3e11e0f7.pcap_ISCX.csv')\n",
    "data3=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_13_2017-ad-kemoge-lookout-0c67d0919e574a6876c73118260368ee.pcap_ISCX.csv')\n",
    "data4=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_13_2017-ad-mobidash-net32-04e1ddcf21e336694f56c2f819f8f467.pcap_ISCX.csv')\n",
    "data5=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_14_2017-ad-Chinese-koodous-4dfb36ce42608ba7692540febfc97b48.pcap_ISCX.csv')\n",
    "data6=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_14_2017-ad-dowgin-gdata-1c.csv')\n",
    "data7=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_14_2017-ad-selfmite-fortinet-3d4b4968621c5f42d835447643f37105.pcap_ISCX.csv')\n",
    "data8=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_14_2017-ad-shuanet-lookout-1ef96d3b8e4b5d44eb4932a6da59b6da.pcap_ISCX.csv')\n",
    "data9=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_15_2017-ad-gooligan-fortinet-1634b1fb3b353019e9d3b7b3d21507ab.pcap_ISCX.csv')\n",
    "data10=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_15_2017-ad-youmi-gdata-3d2f3690fcb3d3836161f12f6f14c633.pcap_ISCX.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:21.575075Z",
     "start_time": "2023-04-03T00:41:21.553115Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5rTOSTV5ezaz",
    "outputId": "3b9e73b9-531d-4ac1-825e-e8e26ae617a3"
   },
   "outputs": [],
   "source": [
    "print(data1.shape)\n",
    "print(data2.shape)\n",
    "print(data3.shape)\n",
    "print(data4.shape)\n",
    "print(data5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:23.180742Z",
     "start_time": "2023-04-03T00:41:23.148849Z"
    }
   },
   "outputs": [],
   "source": [
    "data1 = data1.drop(['Unnamed: 85'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:24.221582Z",
     "start_time": "2023-04-03T00:41:24.199117Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:25.815365Z",
     "start_time": "2023-04-03T00:41:25.785360Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([data1, data2,data3,data4,data5,data6, data7,data8,data9,data10], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:26.714301Z",
     "start_time": "2023-04-03T00:41:26.635276Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:27.750691Z",
     "start_time": "2023-04-03T00:41:27.741671Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:28.516533Z",
     "start_time": "2023-04-03T00:41:28.484885Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:29.732971Z",
     "start_time": "2023-04-03T00:41:29.725838Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data1.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:33.450704Z",
     "start_time": "2023-04-03T00:41:33.431918Z"
    },
    "id": "gGjOpLMvOulA"
   },
   "outputs": [],
   "source": [
    "df=df.drop(['Flow ID','Destination IP','Fwd Packet Length Max','Fwd Packet Length Min','Bwd Packet Length Max','Bwd Packet Length Min','Flow IAT Max','Flow IAT Min','Fwd IAT Max','Fwd IAT Min','Bwd IAT Max','Bwd IAT Min','Min Packet Length','Max Packet Length','Packet Length Variance','Fwd Header Length','Fwd Avg Bytes/Bulk','Fwd Avg Packets/Bulk','Fwd Avg Bulk Rate','Bwd Avg Bytes/Bulk','Bwd Avg Packets/Bulk','Active Max','Active Min','Idle Max','Idle Min','Label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:33.526364Z",
     "start_time": "2023-04-03T00:41:33.494948Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:34.936492Z",
     "start_time": "2023-04-03T00:41:34.718993Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ipaddress\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df['Source IP'] = df['Source IP'].apply(lambda x: int(ipaddress.IPv4Address(x)))\n",
    "\n",
    "# convert the time attribute to a datetime object\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "# encode the time attribute as a numeric feature\n",
    "df['Timestamp'] = df['Timestamp'].astype('int64') / 10**9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:37.127048Z",
     "start_time": "2023-04-03T00:41:37.111386Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:38.530085Z",
     "start_time": "2023-04-03T00:41:38.492410Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:41.740774Z",
     "start_time": "2023-04-03T00:41:41.677621Z"
    },
    "id": "Scc9N2n4LpU0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:43.946043Z",
     "start_time": "2023-04-03T00:41:43.612979Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "DT_entropy = DecisionTreeClassifier(random_state=50)\n",
    "DT_entropy.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:45.234758Z",
     "start_time": "2023-04-03T00:41:45.207780Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Train R^2 score 1:\", DT_entropy.score(X_train, y_train))\n",
    "print(\"Test R^2 score1:\", DT_entropy.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = DT_entropy.predict(X_test)\n",
    "\n",
    "\n",
    "# Compute classification metrics\n",
    "print(\"Accuracy :\",accuracy_score(y_test, y_pred))\n",
    "print ('Confusion Matrix :\\n',confusion_matrix(y_test, y_pred))\n",
    "print ('Classification Report \\n: ',classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Logestic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the multinomial logistic regression model\n",
    "mlr = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "mlr.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = DT_entropy.predict(X_test)\n",
    "\n",
    "\n",
    "# Compute classification metrics\n",
    "print(\"Accuracy :\",accuracy_score(y_test, y_pred))\n",
    "print ('Confusion Matrix :\\n',confusion_matrix(y_test, y_pred))\n",
    "print ('Classification Report \\n: ',classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-03T00:41:49.706010Z",
     "start_time": "2023-04-03T00:41:49.700174Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "sv = svm.SVC(kernel='rbf', C=100,probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sv.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = sv.predict(X_test)\n",
    "\n",
    "\n",
    "# Compute classification metrics\n",
    "print(\"Accuracy :\",accuracy_score(y_test, y_pred))\n",
    "print ('Confusion Matrix :\\n',confusion_matrix(y_test, y_pred))\n",
    "print ('Classification Report \\n: ',classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Train a random forest regressor model\n",
    "rf = RandomForestClassifier(n_estimators=300,criterion='entropy', random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "# Compute classification metrics\n",
    "print(\"Accuracy :\",accuracy_score(y_test, y_pred))\n",
    "print ('Confusion Matrix :\\n',confusion_matrix(y_test, y_pred))\n",
    "print ('Classification Report \\n: ',classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boostingrf = BaggingClassifier(estimator=rf, n_estimators=40)\n",
    "\n",
    "boostingrf.fit(X_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = boostingrf.predict(X_test)\n",
    "\n",
    "\n",
    "# Compute classification metrics\n",
    "print(\"Accuracy :\",accuracy_score(y_test, y_pred))\n",
    "print ('Confusion Matrix :\\n',confusion_matrix(y_test, y_pred))\n",
    "print ('Classification Report \\n: ',classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "\n",
    "# Compute classification metrics\n",
    "print(\"Accuracy :\",accuracy_score(y_test, y_pred))\n",
    "print ('Confusion Matrix :\\n',confusion_matrix(y_test, y_pred))\n",
    "print ('Classification Report \\n: ',classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import  VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_regressor = VotingClassifier(estimators=[('boostingrf', boostingrf), ('knn', knn), ('DT_entropy', DT_entropy)])\n",
    "voting_regressor.fit(X_train, y_train)\n",
    "y_pred = voting_regressor.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "#y_pred = voting_regressor.predict(X_test)\n",
    "\n",
    "\n",
    "# Compute classification metrics\n",
    "print(\"Accuracy :\",accuracy_score(y_test, y_pred))\n",
    "print ('Confusion Matrix :\\n',confusion_matrix(y_test, y_pred))\n",
    "print ('Classification Report \\n: ',classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the model as a file\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(boostingrf, file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/model.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data1=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_13_2017-ad-ewind-koodous-1d.csv')\n",
    "data2=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_13_2017-ad-feiwo-fortinet-04c12809d3b1809c9980bd1e3e11e0f7.pcap_ISCX.csv')\n",
    "data3=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_13_2017-ad-kemoge-lookout-0c67d0919e574a6876c73118260368ee.pcap_ISCX.csv')\n",
    "data4=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_13_2017-ad-mobidash-net32-04e1ddcf21e336694f56c2f819f8f467.pcap_ISCX.csv')\n",
    "data5=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_14_2017-ad-Chinese-koodous-4dfb36ce42608ba7692540febfc97b48.pcap_ISCX.csv')\n",
    "data6=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_14_2017-ad-dowgin-gdata-1c.csv')\n",
    "data7=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_14_2017-ad-selfmite-fortinet-3d4b4968621c5f42d835447643f37105.pcap_ISCX.csv')\n",
    "data8=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_14_2017-ad-shuanet-lookout-1ef96d3b8e4b5d44eb4932a6da59b6da.pcap_ISCX.csv')\n",
    "data9=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_15_2017-ad-gooligan-fortinet-1634b1fb3b353019e9d3b7b3d21507ab.pcap_ISCX.csv')\n",
    "data10=pd.read_csv('C:/Users/cyril/OneDrive/Pictures/SEM 6/assignment/ISM/Project/Dataset/06_15_2017-ad-youmi-gdata-3d2f3690fcb3d3836161f12f6f14c633.pcap_ISCX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1.drop(['Unnamed: 85'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([data1, data2,data3,data4,data5,data6, data7,data8,data9,data10], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Flow ID','Destination IP','Fwd Packet Length Max','Fwd Packet Length Min','Bwd Packet Length Max','Bwd Packet Length Min','Flow IAT Max','Flow IAT Min','Fwd IAT Max','Fwd IAT Min','Bwd IAT Max','Bwd IAT Min','Min Packet Length','Max Packet Length','Packet Length Variance','Fwd Header Length','Fwd Avg Bytes/Bulk','Fwd Avg Packets/Bulk','Fwd Avg Bulk Rate','Bwd Avg Bytes/Bulk','Bwd Avg Packets/Bulk','Active Max','Active Min','Idle Max','Idle Min','Label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipaddress\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df['Source IP'] = df['Source IP'].apply(lambda x: int(ipaddress.IPv4Address(x)))\n",
    "\n",
    "# convert the time attribute to a datetime object\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "# encode the time attribute as a numeric feature\n",
    "df['Timestamp'] = df['Timestamp'].astype('int64') / 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Source_IP = random.uniform(np.min(df['Source IP']),np.max(df['Source IP']))\n",
    "Source_Port = random.uniform(np.min(df['Source Port']),np.max(df['Source Port']))\n",
    "Destination_Port = random.uniform(np.min(df['Destination Port']),np.max(df['Destination Port']))\n",
    "Protocol = random.uniform(np.min(df['Protocol']),np.max(df['Protocol']))\n",
    "Timestamp = random.uniform(np.min(df['Timestamp']),np.max(df['Timestamp']))\n",
    "FlowDuration = random.uniform(np.min(df['Flow Duration']),np.max(df['Flow Duration']))\n",
    "TotalFwdPackets = random.uniform(np.min(df['Total Fwd Packets']),np.max(df['Total Fwd Packets']))\n",
    "TotalBackwardPackets = random.uniform(np.min(df['Total Backward Packets']),np.max(df['Total Backward Packets']))\n",
    "TotalLengthofFwdPackets = random.uniform(np.min(df['Total Length of Fwd Packets']),np.max(df['Total Length of Fwd Packets']))\n",
    "TotalLengthofBwdPackets =random.uniform(np.min(df['Total Length of Bwd Packets']),np.max(df['Total Length of Bwd Packets']))\n",
    "FwdPacketLengthMean = random.uniform(np.min(df['Fwd Packet Length Mean']),np.max(df['Fwd Packet Length Mean']))\n",
    "FwdPacketLengthStd = random.uniform(np.min(df['Fwd Packet Length Std']),np.max(df['Fwd Packet Length Std']))\n",
    "BwdPacketLengthMean = random.uniform(np.min(df['Bwd Packet Length Mean']),np.max(df['Bwd Packet Length Mean']))\n",
    "BwdPacketLengthStd = random.uniform(np.min(df['Bwd Packet Length Std']),np.max(df['Bwd Packet Length Std']))\n",
    "FlowBytes = random.uniform(np.min(df['Flow Bytes/s']),np.max(df['Flow Bytes/s']))\n",
    "FlowPackets = random.uniform(np.min(df['Flow Packets/s']),np.max(df['Flow Packets/s']))\n",
    "FlowIATMean = random.uniform(np.min(df['Flow IAT Mean']),np.max(df['Flow IAT Mean']))\n",
    "FlowIATStd = random.uniform(np.min(df['Flow IAT Std']),np.max(df['Flow IAT Std']))\n",
    "FwdIATTotal = random.uniform(np.min(df['Fwd IAT Total']),np.max(df['Fwd IAT Total']))\n",
    "FwdIATMean = random.uniform(np.min(df['Fwd IAT Mean']),np.max(df['Fwd IAT Mean']))\n",
    "FwdIATStd = random.uniform(np.min(df['Fwd IAT Std']),np.max(df['Fwd IAT Std']))\n",
    "BwdIATTotal = random.uniform(np.min(df['Bwd IAT Total']),np.max(df['Bwd IAT Total']))\n",
    "BwdIATMean = random.uniform(np.min(df['Bwd IAT Mean']),np.max(df['Bwd IAT Mean']))\n",
    "BwdIATStd = random.uniform(np.min(df['Bwd IAT Std']),np.max(df['Bwd IAT Std']))\n",
    "FwdPSHFlags = random.uniform(np.min(df['Fwd PSH Flags']),np.max(df['Fwd PSH Flags']))\n",
    "BwdPSHFlags = random.uniform(np.min(df['Bwd PSH Flags']),np.max(df['Bwd PSH Flags']))\n",
    "FwdURGFlags = random.uniform(np.min(df['Fwd URG Flags']),np.max(df['Fwd URG Flags']))\n",
    "BwdURGFlags = random.uniform(np.min(df['Bwd URG Flags']),np.max(df['Bwd URG Flags']))\n",
    "BwdHeaderLength = random.uniform(np.min(df['Bwd Header Length']),np.max(df['Bwd Header Length']))\n",
    "FwdPackets = random.uniform(np.min(df['Fwd Packets/s']),np.max(df['Fwd Packets/s']))\n",
    "BwdPackets =random.uniform(np.min(df['Bwd Packets/s']),np.max(df['Bwd Packets/s']))\n",
    "PacketLengthMean=random.uniform(np.min(df['Packet Length Mean']),np.max(df['Packet Length Mean']))\n",
    "PacketLengthStd=random.uniform(np.min(df['Packet Length Std']),np.max(df['Packet Length Std']))\n",
    "FINFlagCount=random.uniform(np.min(df['FIN Flag Count']),np.max(df['FIN Flag Count']))\n",
    "SYNFlagCount=random.uniform(np.min(df['SYN Flag Count']),np.max(df['SYN Flag Count']))\n",
    "RSTFlagCount=random.uniform(np.min(df['RST Flag Count']),np.max(df['RST Flag Count']))\n",
    "PSHFlagCount=random.uniform(np.min(df['PSH Flag Count']),np.max(df['PSH Flag Count']))\n",
    "ACKFlagCount=random.uniform(np.min(df['ACK Flag Count']),np.max(df['ACK Flag Count']))\n",
    "URGFlagCount=random.uniform(np.min(df['URG Flag Count']),np.max(df['URG Flag Count']))\n",
    "CWEFlagCount=random.uniform(np.min(df['CWE Flag Count']),np.max(df['CWE Flag Count']))\n",
    "ECEFlagCount=random.uniform(np.min(df['ECE Flag Count']),np.max(df['ECE Flag Count']))\n",
    "DownUpRatio=random.uniform(np.min(df['Down/Up Ratio']),np.max(df['Down/Up Ratio']))\n",
    "AveragePacketSize=random.uniform(np.min(df['Average Packet Size']),np.max(df['Average Packet Size']))\n",
    "AvgFwdSegmentSize=random.uniform(np.min(df['Avg Fwd Segment Size']),np.max(df['Avg Fwd Segment Size']))\n",
    "AvgBwdSegmentSize=random.uniform(np.min(df['Avg Bwd Segment Size']),np.max(df['Avg Bwd Segment Size']))\n",
    "FwdHeaderLength=32\n",
    "BwdAvgBulkRate=random.uniform(np.min(df['Bwd Avg Bulk Rate']),np.max(df['Bwd Avg Bulk Rate']))\n",
    "SubflowFwdPackets=random.uniform(np.min(df['Subflow Fwd Packets']),np.max(df['Subflow Fwd Packets']))\n",
    "SubflowFwdBytes=random.uniform(np.min(df['Subflow Fwd Bytes']),np.max(df['Subflow Fwd Bytes']))\n",
    "SubflowBwdPackets=random.uniform(np.min(df['Subflow Bwd Packets']),np.max(df['Subflow Bwd Packets']))\n",
    "SubflowBwdBytes=random.uniform(np.min(df['Subflow Bwd Bytes']),np.max(df['Subflow Bwd Bytes']))\n",
    "Init_Win_bytes_forward=random.uniform(np.min(df['Init_Win_bytes_forward']),np.max(df['Init_Win_bytes_forward']))\n",
    "Init_Win_bytes_backward=random.uniform(np.min(df['Init_Win_bytes_backward']),np.max(df['Init_Win_bytes_backward']))\n",
    "act_data_pkt_fwd=random.uniform(np.min(df['act_data_pkt_fwd']),np.max(df['act_data_pkt_fwd']))\n",
    "min_seg_size_forward=random.uniform(np.min(df['min_seg_size_forward']),np.max(df['min_seg_size_forward']))\n",
    "ActiveMean=random.uniform(np.min(df['Active Mean']),np.max(df['Active Mean']))\n",
    "ActiveStd=random.uniform(np.min(df['Active Std']),np.max(df['Active Std']))\n",
    "IdleMean=random.uniform(np.min(df['Idle Mean']),np.max(df['Idle Mean']))\n",
    "IdleStd=random.uniform(np.min(df['Idle Std']),np.max(df['Idle Std']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.array([Source_IP,\n",
    "Source_Port,\n",
    "Destination_Port,\n",
    "Protocol,\n",
    "Timestamp,\n",
    "FlowDuration,\n",
    "TotalFwdPackets,\n",
    "TotalBackwardPackets,\n",
    "TotalLengthofFwdPackets,\n",
    "TotalLengthofBwdPackets,\n",
    "FwdPacketLengthMean,\n",
    "FwdPacketLengthStd,\n",
    "BwdPacketLengthMean,\n",
    "BwdPacketLengthStd,\n",
    "FlowBytes,\n",
    "FlowPackets,\n",
    "FlowIATMean,\n",
    "FlowIATStd,\n",
    "FwdIATTotal,\n",
    "FwdIATMean,\n",
    "FwdIATStd,\n",
    "BwdIATTotal,\n",
    "BwdIATMean,\n",
    "BwdIATStd,\n",
    "FwdPSHFlags,\n",
    "BwdPSHFlags,\n",
    "FwdURGFlags,\n",
    "BwdURGFlags,\n",
    "BwdHeaderLength,\n",
    "FwdPackets,\n",
    "BwdPackets,\n",
    "PacketLengthMean,\n",
    "PacketLengthStd,\n",
    "FINFlagCount,\n",
    "SYNFlagCount,\n",
    "RSTFlagCount,\n",
    "PSHFlagCount,\n",
    "ACKFlagCount,\n",
    "URGFlagCount,\n",
    "CWEFlagCount,\n",
    "ECEFlagCount,\n",
    "DownUpRatio,\n",
    "AveragePacketSize,\n",
    "AvgFwdSegmentSize,\n",
    "AvgBwdSegmentSize,\n",
    "FwdHeaderLength,\n",
    "BwdAvgBulkRate,\n",
    "SubflowFwdPackets,\n",
    "SubflowFwdBytes,\n",
    "SubflowBwdPackets,\n",
    "SubflowBwdBytes,\n",
    "Init_Win_bytes_forward,\n",
    "Init_Win_bytes_backward,\n",
    "act_data_pkt_fwd,\n",
    "min_seg_size_forward,\n",
    "ActiveMean,\n",
    "ActiveStd,\n",
    "IdleMean,\n",
    "IdleStd]).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cyril\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but BaggingClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADWARE_KEMOGE']\n"
     ]
    }
   ],
   "source": [
    "print(label_encoder.inverse_transform(y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
